# docker-compose.yml

# version: '3.8'

services:
  # --------------------------------------------------------------------------
  # Hadoop NameNode Service
  # --------------------------------------------------------------------------
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    hostname: namenode
    container_name: namenode
    ports:
      - "9870:9870"
      # - "9000:9000"
    volumes:
      - namenode-data:/hadoop/dfs/name
    environment:
    - CLUSTER_NAME=test-cluster
    - HDFS_USER=hdfs
    - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
    env_file:
      - ./hadoop-conf/hadoop.env
    networks:
      - big-data-net
    healthcheck:
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 1g

  # --------------------------------------------------------------------------
  # Hadoop DataNode Service
  # --------------------------------------------------------------------------
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    hostname: datanode
    container_name: datanode
    volumes:
      - datanode-data:/hadoop/dfs/data      
      # - ./core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml:ro
      # - ./hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml:ro
    environment:
      - CLUSTER_NAME=test-cluster
      - HDFS_USER=hdfs
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_datanode_hostname=datanode
      - HDFS_CONF_dfs_datanode_use_datanode_hostname=true
    env_file:
      - ./hadoop-conf/hadoop.env
    networks:
      - big-data-net
    depends_on:
      namenode:
        condition: service_healthy
    mem_limit: 2g

  # --------------------------------------------------------------------------
  # MariaDB Service (New Hive Metastore)
  # --------------------------------------------------------------------------
  mariadb:
    image: mariadb:10.6
    hostname: mariadb
    container_name: mariadb
    ports:
      - "3306:3306"
    volumes:
      - mariadb-data:/var/lib/mysql
    environment:
      - MARIADB_ROOT_PASSWORD=your_root_password
      - MARIADB_DATABASE=hive_metastore
      - MARIADB_USER=hive
      - MARIADB_PASSWORD=hive_password
    networks:
      - big-data-net
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost", "-u", "root", "-p$$MARIADB_ROOT_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 512m

  # --------------------------------------------------------------------------
  # Hive Service (Metastore and HiveServer2)
  # --------------------------------------------------------------------------
  hive-server:
    image: apache/hive:3.1.3
    container_name: hive-server
    hostname: hive-server
    ports:
      - "10000:10000"
      - "9083:9083"
    volumes:
      - ./hadoop-conf/hive-start.sh:/usr/local/bin/hive-start.sh:ro
      - ./hadoop-conf/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
      - ./hadoop-conf/lib/mysql-connector-j-8.4.0.jar:/opt/hive/lib/mysql-connector-j-8.4.0.jar:ro
      - ./hadoop-conf:/opt/hadoop/etc/hadoop:ro     # <- mount the whole dir
      - ./hadoop-conf/core-site.xml:/etc/hadoop/conf/core-site.xml:ro
    environment:
      HIVE_CONF_DIR: /opt/hive/conf
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      HIVE_SERVER2_HEAPSIZE: 6144              # <- add this
      HADOOP_CLIENT_OPTS: "-Xmx4g"             # <- also boost client JVM heap
    networks:
      - big-data-net
    depends_on:
      namenode:
        condition: service_healthy
      mariadb:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "/opt/hive/bin/beeline -u 'jdbc:hive2://127.0.0.1:10000/' -n hive -e 'show databases' >/dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 10
      start_period: 150s

    entrypoint: ["/usr/local/bin/hive-start.sh"]
    
    

  # --------------------------------------------------------------------------
  # MongoDB Service
  # --------------------------------------------------------------------------
  mongodb:
    image: mongo:6.0
    hostname: mongodb
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
    environment:
      - MONGO_INITDB_ROOT_USERNAME=mongouser
      - MONGO_INITDB_ROOT_PASSWORD=mongopassword
    networks:
      - big-data-net
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')", "--quiet" ]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 512m

  # --------------------------------------------------------------------------
  # JupyterLab Service
  # --------------------------------------------------------------------------
  jupyterlab:
    image: jupyter/scipy-notebook:latest
    hostname: jupyterlab
    container_name: jupyterlab
    ports:
      - "8888:8888"
    volumes:
      # Mount the local notebooks directory
      - ./notebooks:/home/jovyan/work
      # Add this line to mount your local data directory
      - ./data:/home/jovyan/work/data
      - "/mnt/c/Users/harry/Desktop/工作/DE/Data-Quality-Metadata-Deployment-Practices/dq:/home/jovyan/work/dq_ext"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
      - NB_UID=1000
      - NB_GID=100
      - HADOOP_NAMENODE_HOST=namenode
      - HIVE_SERVER_HOST=hive-server
      - HIVE_SERVER_PORT=10000
      - MARIADB_HOST=mariadb
      - MARIADB_PORT=3306
      - MARIADB_USER=hive
      - MARIADB_PASSWORD=hive_password
      - MONGODB_HOST=mongodb
      - MONGODB_PORT=27017
      - MONGODB_USER=mongouser
      - MONGODB_PASSWORD=mongopassword
    networks:
      - big-data-net
    depends_on:
      namenode:
        condition: service_healthy
      hive-server:
        condition: service_healthy
      mariadb:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    mem_limit: 1.5g
    command: start-notebook.sh --NotebookApp.token='' --NotebookApp.allow_origin='*'

  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    volumes:
      - ./data/minio:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - big-data-net
    healthcheck:
      # MinIO exposes readiness at /minio/health/ready
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/minio/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 20s
  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    networks:
      - big-data-net
    restart: "no"
    entrypoint: >
      /bin/sh -lc "
        mc alias set local http://minio:9000 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD &&
        mc mb -p local/rt-stream || true &&
        mc ls local
      "

  kafka:
    image: bitnami/kafka:3.5
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_OUTSIDE_PORT:-9094}:9094"
    environment:
      - KAFKA_BROKER_ID=${KAFKA_BROKER_ID}
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INSIDE://:9092,OUTSIDE://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=INSIDE://kafka:9092,OUTSIDE://localhost:${KAFKA_OUTSIDE_PORT:-9094}
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INSIDE
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1   # single-broker 
    networks:
      - big-data-net
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka
      - zookeeper
    networks:
      - big-data-net

  zookeeper:
    image: bitnami/zookeeper:3.8
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks:
      - big-data-net
  python-producer:
    image: python:3.11-slim
    depends_on:
      - kafka
    working_dir: /app
    volumes:
      - .:/app
    # Share the default docker compose network with kafka
    # so 'kafka:9092' is resolvable.
    networks:
      - big-data-net
  spark:
    build:
      context: ./docker/spark
    image: local/spark:3.5-python
    container_name: spark
    # image: bitnami/spark:3.5
    user: "0:0"
    working_dir: /app
    command: ["bash","-lc","sleep infinity"]
    environment:
      - HOME=/tmp/spark-home
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - .:/app
      - spark_ivy:/tmp/spark-home/.ivy2   # persist Ivy cache to speed up future runs
      - spark_m2:/tmp/spark-home/.m2
    networks:
      - big-data-net


# --------------------------------------------------------------------------
# Docker Volumes for Persistent Data
# --------------------------------------------------------------------------
volumes:
  namenode-data:
  datanode-data:
  mariadb-data:
  mongodb-data:
  spark_ivy:
  spark_m2:

# --------------------------------------------------------------------------
# Docker Network for Inter-Service Communication
# --------------------------------------------------------------------------
networks:
  big-data-net:
    driver: bridge